{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCR.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNNweRMLxMf/OSFfBWxbuHF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/milmor/deep-puma/blob/main/Image-preprocessing/OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwd8EdMNxgyM"
      },
      "source": [
        "### Acceso a drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZUUqTBYxXO6",
        "outputId": "a23d10b0-90fc-4c87-a986-041a511ead8f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPDzCAKi0lwX"
      },
      "source": [
        "# Bibliotecas "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA-T4q-z1CBb",
        "outputId": "7ceb5e8a-6532-43e8-bdf8-4767ab60f19d"
      },
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!cp drive/MyDrive/HackathonRIIAA2021/Data/spa.traineddata /usr/share/tesseract-ocr/4.00/tessdata/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 1s (4,372 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 148486 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.8.tar.gz (14 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.8-py2.py3-none-any.whl size=14072 sha256=65de93df4417e669fb8878824a7e257a9bae2fc07127b68cc14a9be9733422ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/89/b9/3f11250225d0f90e5454fcc30fd1b7208db226850715aa9ace\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX9vtl2Wxe4T"
      },
      "source": [
        "import os \n",
        "import pytesseract as ocr\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTsmbaqX5vEn"
      },
      "source": [
        "### Función para procesar imagenes y utilizar Tessearct-OCR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JMCGafZ5ueE"
      },
      "source": [
        "def get_processed_images(src_path, processed_path, texts_path, missed_path,bin_option=True):\n",
        "  source = [f for f in os.listdir(src_path) if os.path.isfile(os.path.join(src_path, f))]\n",
        "  print('\\n[INFO] Se encontraron {} imagenes para procesar.\\n'.format(len(source)))\n",
        "  \n",
        "  for index in tqdm(range(len(source))):\n",
        "    # Lectura y escalado de imagenes #\n",
        "    image_name = source[index].split('.')[0]\n",
        "    image = cv.imread('{}{}'.format(src_path,source[index]))\n",
        "    image = cv.resize(image, None, fx=1.3, fy=1.3, interpolation=cv.INTER_CUBIC)\n",
        "    \n",
        "    \"\"\"\n",
        "    Preprocesamiento de imagenes\n",
        "    \"\"\"\n",
        "    # Eliminación de ruido causado por sombras en las imagenes #\n",
        "    gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "    dilated_image = cv.dilate(gray_image, np.ones((7,7), np.uint8))\n",
        "    blur_image = cv.medianBlur(dilated_image,21)\n",
        "    diff_image = 255 - cv.absdiff(gray_image, blur_image)\n",
        "    norm_image = diff_image.copy()\n",
        "    cv.normalize(diff_image, norm_image, alpha=0, beta=255, norm_type=cv.NORM_MINMAX, dtype=cv.CV_8UC1)\n",
        "    thr_img = cv.threshold(norm_image, 230, 0, cv.THRESH_TRUNC)[1]\n",
        "    cv.normalize(thr_img, thr_img, alpha=0, beta=255, norm_type=cv.NORM_MINMAX, dtype=cv.CV_8UC1)\n",
        "    bin_image = cv.threshold(thr_img, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)[1]\n",
        "    \n",
        "    # detección de texto #\n",
        "    bin_image_inv = cv.threshold(thr_img, 0, 255, cv.THRESH_OTSU | cv.THRESH_BINARY_INV)[1]\n",
        "    rect_kernel = cv.getStructuringElement(cv.MORPH_RECT, (90, 90))\n",
        "    dilation = cv.dilate(bin_image_inv, rect_kernel, iterations = 1)\n",
        "    \n",
        "    contours, hierarchy = cv.findContours(dilation, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n",
        "    if bin_option:\n",
        "        image_copy = bin_image.copy()\n",
        "    else:\n",
        "        image_copy = gray_image.copy()\n",
        "    count = -1\n",
        "    for cnt in contours:\n",
        "        count +=1\n",
        "        x,y,w,h = cv.boundingRect(cnt)\n",
        "        cropped = image_copy[y:y + h, x:x + w]\n",
        "        h,w = cropped.shape\n",
        "        if h>490 and w>490:\n",
        "          try:\n",
        "            text = ocr.image_to_string(cropped, lang='spa')\n",
        "            if len(text) > 0:\n",
        "              cv.imwrite('{}{}_processed_{}.png'.format(processed_path,image_name,count), cropped)\n",
        "              textfile = open('{}{}_text.txt'.format(texts_path,image_name),'a')\n",
        "              textfile.write(text)\n",
        "              textfile.close()\n",
        "          except:\n",
        "            cv.imwrite('{}{}_processed_{}.png'.format(missed_path,image_name,count), cropped)\n",
        "            continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSC1bpCRxfD9"
      },
      "source": [
        "IMAGES_PATH = 'drive/MyDrive/Datos - Hackathon JusticIA/Fichas_manual/'\n",
        "PROCESSED_PATH = 'drive/MyDrive/HackathonRIIAA2021/Processed_images/Fichas_manual/'\n",
        "MISSED_IMAGES_PATH = 'drive/MyDrive/HackathonRIIAA2021/Missed_images/Fichas_manual/'\n",
        "TEXTS_PATH = 'drive/MyDrive/HackathonRIIAA2021/Texts/Fichas_manual/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4h0xPLSxfI_",
        "outputId": "2c42cf10-26c8-44ef-94a3-10fd3b8a3f62"
      },
      "source": [
        "get_processed_images(src_path=IMAGES_PATH, processed_path=PROCESSED_PATH, texts_path=TEXTS_PATH, missed_path=MISSED_IMAGES_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[INFO] Se encontraron 1000 imagenes para procesar.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [2:50:25<00:00, 10.23s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JloNT3qoC7q7"
      },
      "source": [
        "IMAGES_PATH = 'drive/MyDrive/Datos - Hackathon JusticIA/Fichas_auto/'\n",
        "PROCESSED_PATH = 'drive/MyDrive/HackathonRIIAA2021/Processed_images/Fichas_auto/'\n",
        "MISSED_IMAGES_PATH = 'drive/MyDrive/HackathonRIIAA2021/Missed_images/Fichas_auto/'\n",
        "TEXTS_PATH = 'drive/MyDrive/HackathonRIIAA2021/Texts/Fichas_auto/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdYXjI_AC78q",
        "outputId": "fe14550d-1c44-4984-a341-b6c20e34349d"
      },
      "source": [
        "get_processed_images(src_path=IMAGES_PATH, processed_path=PROCESSED_PATH, texts_path=TEXTS_PATH, missed_path=MISSED_IMAGES_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[INFO] Se encontraron 1000 imagenes para procesar.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [2:55:25<00:00, 10.53s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}